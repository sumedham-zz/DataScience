{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Models to Predict March Madness Rankings\n",
    "\n",
    "\n",
    "March Madness, also known as the NCAA Division I Men's Basketball Tournament happens annually in the month of March. Depending on which teams performed the best in the season, the top 32 are selected to compete in the tournament and play each other in a bracket for the winners trophy. Although March Madness 2018 is already over, our team wanted to see which model would do a better job at predicting team rankings/winners. We decided to look at the Elo Model as well as use logistic regression with features we extracted in order to find a trend. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the Data\n",
    "\n",
    "In order to scrape data, we used www.sports-reference.com/cbb (cbb = college basketball). We utilized the BeautifulSoup library to extract the features that we thought we would need for both models. In the following code the features extracted are in the _featuresWanted_ set. A typical page that we would scrape from looks like the following: \n",
    "\n",
    "\n",
    "<img src=\"files/cbbstatsex.png\">\n",
    "\n",
    "This data displays Villanova's game history for the year 2018 [found here](https://www.sports-reference.com/cbb/schools/villanova/2018-schedule.html). We used Beautiful Soup to gather all the table data and format it in a data frame. Because the scraping usually takes ~10 minutes, the code was run once and put into a csv file, which we later used to do our data analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akhilkemburu/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/akhilkemburu/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "{'bryant', 'wake-forest', 'arkansas-state', 'georgia', 'st-bonaventure', 'high-point', 'southern-mississippi', 'seton-hall', 'norfolk-state', 'saint-peters', 'stetson', 'alabama-birmingham', 'cal-state-bakersfield', 'new-hampshire', 'south-alabama', 'albany-ny', 'stephen-f-austin', 'jacksonville', 'pittsburgh', 'iowa-state', 'southern-utah', 'kent-state', 'texas', 'old-dominion', 'cincinnati', 'fairleigh-dickinson', 'tennessee-martin', 'oklahoma-state', 'tennessee-tech', 'colorado', 'green-bay', 'college-of-charleston', 'florida', 'furman', 'longwood', 'central-michigan', 'delaware', 'california-riverside', 'george-mason', 'william-mary', 'bradley', 'texas-southern', 'massachusetts', 'california', 'prairie-view', 'tennessee-state', 'charlotte', 'gardner-webb', 'louisiana-lafayette', 'central-arkansas', 'james-madison', 'texas-tech', 'drake', 'monmouth', 'northern-illinois', 'south-carolina-state', 'clemson', 'rutgers', 'kentucky', 'minnesota', 'south-carolina-upstate', 'seattle', 'milwaukee', 'california-santa-barbara', 'fresno-state', 'middle-tennessee', 'san-diego', 'louisiana-tech', 'cleveland-state', 'portland', 'alabama-am', 'arkansas-little-rock', 'long-beach-state', 'california-irvine', 'washington-state', 'southern-methodist', 'michigan', 'illinois-state', 'kennesaw-state', 'san-francisco', 'stony-brook', 'virginia-tech', 'sacred-heart', 'hofstra', 'st-johns-ny', 'wyoming', 'winthrop', 'toledo', 'siena', 'saint-louis', 'hampton', 'tulane', 'navy', 'fairfield', 'central-florida', 'illinois', 'southeastern-louisiana', 'duquesne', 'nebraska-omaha', 'detroit-mercy', 'brown', 'southern-illinois', 'montana-state', 'loyola-marymount', 'jacksonville-state', 'michigan-state', 'ipfw', 'eastern-michigan', 'miami-fl', 'evansville', 'creighton', 'indiana-state', 'depaul', 'stanford', 'abilene-christian', 'auburn', 'ball-state', 'virginia', 'maryland-eastern-shore', 'mount-st-marys', 'hawaii', 'rice', 'maryland-baltimore-county', 'njit', 'north-carolina-greensboro', 'la-salle', 'texas-state', 'buffalo', 'virginia-commonwealth', 'brigham-young', 'tulsa', 'northeastern', 'elon', 'morgan-state', 'rhode-island', 'alabama-state', 'south-florida', 'cal-state-fullerton', 'binghamton', 'nevada', 'texas-am-corpus-christi', 'rider', 'lafayette', 'texas-am', 'south-carolina', 'northern-kentucky', 'north-carolina', 'savannah-state', 'eastern-kentucky', 'grambling', 'syracuse', 'vermont', 'denver', 'wright-state', 'boise-state', 'davidson', 'oakland', 'vanderbilt', 'radford', 'arizona-state', 'southern-illinois-edwardsville', 'louisiana-monroe', 'mississippi-valley-state', 'drexel', 'east-carolina', 'penn-state', 'utah-state', 'iupui', 'boston-college', 'houston', 'ohio-state', 'notre-dame', 'alabama', 'portland-state', 'wichita-state', 'gonzaga', 'oregon-state', 'northern-arizona', 'southeast-missouri-state', 'texas-el-paso', 'george-washington', 'weber-state', 'alcorn-state', 'north-carolina-state', 'iona', 'western-kentucky', 'utah-valley', 'northern-iowa', 'long-island-university', 'troy', 'florida-international', 'canisius', 'marshall', 'belmont', 'murray-state', 'eastern-washington', 'pepperdine', 'xavier', 'miami-oh', 'providence', 'samford', 'coppin-state', 'cal-state-northridge', 'mercer', 'north-florida', 'sam-houston-state', 'georgia-southern', 'louisiana-state', 'wagner', 'butler', 'new-mexico-state', 'cal-poly', 'new-mexico', 'chattanooga', 'ucla', 'colgate', 'maine', 'saint-josephs', 'south-dakota', 'texas-san-antonio', 'appalachian-state', 'austin-peay', 'memphis', 'north-dakota-state', 'harvard', 'southern', 'cornell', 'north-carolina-asheville', 'american', 'dartmouth', 'florida-gulf-coast', 'north-carolina-at', 'nicholls-state', 'youngstown-state', 'south-dakota-state', 'western-michigan', 'santa-clara', 'dayton', 'northwestern', 'purdue', 'bethune-cookman', 'texas-arlington', 'idaho-state', 'duke', 'citadel', 'texas-pan-american', 'california-davis', 'missouri-state', 'akron', 'manhattan', 'iowa', 'morehead-state', 'marist', 'niagara', 'temple', 'missouri-kansas-city', 'western-illinois', 'st-francis-ny', 'north-carolina-central', 'west-virginia', 'bucknell', 'howard', 'jackson-state', 'chicago-state', 'presbyterian', 'army', 'colorado-state', 'wofford', 'northern-colorado', 'maryland', 'north-texas', 'villanova', 'marquette', 'saint-marys-ca', 'hartford', 'oral-roberts', 'lehigh', 'bowling-green-state', 'lipscomb', 'princeton', 'nebraska', 'pennsylvania', 'arizona', 'mississippi', 'north-dakota', 'richmond', 'massachusetts-lowell', 'baylor', 'charleston-southern', 'utah', 'washington', 'arkansas-pine-bluff', 'yale', 'air-force', 'fordham', 'ohio', 'oklahoma', 'western-carolina', 'valparaiso', 'coastal-carolina', 'pacific', 'montana', 'florida-state', 'illinois-chicago', 'georgia-state', 'lamar', 'towson', 'san-jose-state', 'florida-atlantic', 'san-diego-state', 'central-connecticut-state', 'texas-christian', 'delaware-state', 'idaho', 'florida-am', 'houston-baptist', 'saint-francis-pa', 'arkansas', 'liberty', 'sacramento-state', 'northwestern-state', 'loyola-md', 'nevada-las-vegas', 'north-carolina-wilmington', 'grand-canyon', 'georgia-tech', 'southern-california', 'incarnate-word', 'loyola-il', 'robert-morris', 'missouri', 'mcneese-state', 'kansas-state', 'virginia-military-institute', 'campbell', 'columbia', 'eastern-illinois', 'kansas', 'quinnipiac', 'georgetown', 'boston-university', 'tennessee', 'oregon', 'indiana', 'wisconsin', 'connecticut', 'holy-cross', 'louisville', 'mississippi-state', 'east-tennessee-state', 'new-orleans'}\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def getSchools():\n",
    "    url = \"https://www.sports-reference.com/cbb/seasons/2018-school-stats.html\"\n",
    "    page = urlopen(url).read()\n",
    "    soup = BeautifulSoup(page)\n",
    "    count  = 0\n",
    "    table = soup.find(\"tbody\")\n",
    "    school_dict = dict()\n",
    "    for row in table.findAll('td', {\"data-stat\": \"school_name\"}):\n",
    "        school_name = row.getText()\n",
    "        for a in row.find_all('a', href=True):\n",
    "            link = a['href'].strip()\n",
    "            name = link[13:].split(\"/\")[0]\n",
    "            school_dict[name] = school_name\n",
    "            \n",
    "    return school_dict\n",
    "\n",
    "def getDfs():\n",
    "    school_set = getSchools()\n",
    "    dfs = []\n",
    "    final_df=pd.DataFrame()\n",
    "    for school in school_set: \n",
    "        url = \"https://www.sports-reference.com/cbb/schools/\" + school + \"/2018-schedule.html\"\n",
    "        page = urlopen(url).read()\n",
    "        soup = BeautifulSoup(page)\n",
    "        count = 0 \n",
    "        pre_df = dict()\n",
    "        school_set = getSchools()\n",
    "        table = soup.find(\"tbody\")\n",
    "        featuresWanted =  {'opp_name', 'pts', 'opp_pts', \n",
    "                           'game_location','game_result','overtimes','wins','losses', 'date_game'} #add more features here!!\n",
    "\n",
    "        rows = table.findChildren(['tr'])\n",
    "        for row in rows:\n",
    "            if (row.find('th', {\"scope\":\"row\"}) != None):\n",
    "\n",
    "                for f in featuresWanted:\n",
    "                    cell = row.find(\"td\",{\"data-stat\": f})\n",
    "\n",
    "                    a = cell.text.strip().encode()\n",
    "                    text=a.decode(\"utf-8\")\n",
    "                    if f in pre_df:\n",
    "                        pre_df[f].append(text)\n",
    "                    else:\n",
    "                        pre_df[f]=[text]\n",
    "            \n",
    "        df = pd.DataFrame.from_dict(pre_df)\n",
    "        df[\"opp_name\"]= df[\"opp_name\"].apply(lambda row: (row.split(\"(\")[0]).rstrip())\n",
    "        df[\"school_name\"]=school_set[school]\n",
    "        df[\"school_name\"] = df[\"school_name\"].apply(lambda row: (row.split(\"(\")[0]).rstrip())\n",
    "        final_df=pd.concat([final_df,df])\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def csvDump():\n",
    "    df=getDfs()\n",
    "    df.to_csv(\"scraped_data.csv\")\n",
    "    \n",
    "    \n",
    "csvDump()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the csv, our csv (in this same folder, called scraped_data.csv contained data about all games that were played in the 2017-2018 season. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## The Elo Model \n",
    "\n",
    "The Elo Model is a way of creating a rating system for zero-sum games - games that only have one winner and one loser (e.g. basketball, hockey, football, tennis, etc.) The system uses the following method:\n",
    "\n",
    "The algorithm works in the following way: \n",
    "\n",
    "Each team begins with the same ranking. The standard across most sports is ~1000-1500. We started out with *1200*, which was a common trend amongst others across the internet who had also used Elo Rankings for other sports. We then calculate the probability of each team winning with the following equation:\n",
    "\n",
    "**Team1 Probability = (1.0 / (1.0 + 10^((Team1_Rating – Team2_Rating) / 400)))**\n",
    "\n",
    "**Team2 Probability  = (1.0 / (1.0 + 10^((Team2_Rating – Team1_Rating) / 400)))**\n",
    "\n",
    "\n",
    "We can see that Team1 Probabilty + Team2 Probabiilty = 1.0. The '400' is a standardized constant in Elo Rankings[(1)](https://en.wikipedia.org/wiki/Elo_rating_system)\n",
    "\n",
    "When a game is played, we can update the rankings of both teams using the following equation: \n",
    "\n",
    "**Team1_Rating = Team1_Rating + K*(Team1_Score – Team1_Probability)**\n",
    "\n",
    "**Team2_Rating = Team2_Rating + K*(Team2_Score – Team2_Probability)**\n",
    "\n",
    "Here, the scores are determined by the outcome of the game:\n",
    "\n",
    "win = 1.0\n",
    "draw = 0.5\n",
    "loss = 0.0\n",
    "\n",
    "The K factor is a numerical value that \"determines how much the Elo rating should change following a match result\"[(2)](www.betfair.com.au). Across literature and the internet, a common k-factor for basketball has been 20 (Used by FiveThirtyEight and others). We can actually create a K=factor that depeonds on the nubmer of matches played. (More on this later). \n",
    "\n",
    "\n",
    "The following Elo class creates an Elo ranking for each team and updates it everytime a game is played. It will be used for data analysis on the data we scraped earlier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "WIN = 1.\n",
    "DRAW = 0.5\n",
    "LOSS = 0.\n",
    "\n",
    "https://www.geeksforgeeks.org/elo-rating-algorithm/\n",
    "\n",
    "'''\n",
    "#: Default K-factor.\n",
    "K_FACTOR = 20\n",
    "#: Default rating class.\n",
    "RATING_CLASS = float\n",
    "#: Default initial rating.\n",
    "INITIAL_RATING = 1200\n",
    "#: Default Beta value.\n",
    "BETA = 200\n",
    "\n",
    "\n",
    "class Elo(object):\n",
    "    #initialize object\n",
    "    def __init__(self, teamName, kFactor = K_FACTOR, rating = INITIAL_RATING, beta = BETA):\n",
    "        self.teamName = teamName\n",
    "        self.kFactor = kFactor\n",
    "        self.rating = rating \n",
    "        self.pWin = None\n",
    "        self.beta = 2*BETA\n",
    "        self.matches = 0 \n",
    "\n",
    "    def calcPWin(self, oppRating): #expected\n",
    "        pwin = 1/(1+1000.00**((self.rating - oppRating)/self.beta))\n",
    "        self.pWin = pwin\n",
    "        return pwin\n",
    "\n",
    "    def game(self, outcome, oppRating): #1 for win, 0 for loss, \n",
    "        pwin =self.calcPWin(oppRating)\n",
    "        self.rating = self.rating - self.kFactor*(outcome - pwin)\n",
    "        self.matches+=1\n",
    "        return True\n",
    "\n",
    "    def getPWin(self):\n",
    "        return self.pWin\n",
    "\n",
    "    def getRating(self):\n",
    "        return self.rating\n",
    "\n",
    "    def setKFactor(self, k):\n",
    "        self.kFactor = k \n",
    "\n",
    "\n",
    "# TEST\n",
    "\n",
    "# elo = Elo(\"villanova\")\n",
    "# print(elo.kFactor)\n",
    "# x = elo.game(0, 1200)\n",
    "# print(elo.getRating())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'new_data.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-091f9a6cc7ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mschoolDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-091f9a6cc7ed>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"new_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_game'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_game\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'new_data.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def removeNCAA(x):\n",
    "    if(\"NCAA\" in x):\n",
    "        return x[:-5]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def main(): \n",
    "    df = pd.read_csv(\"scraped_data.csv\")\n",
    "    df.drop(['Unnamed: 0'], axis = 1, inplace=True)\n",
    "    df['date_game'] =pd.to_datetime(df.date_game)\n",
    "    df[\"school_name\"].apply(removeNCAA)\n",
    "    print(df[\"school_name\"])\n",
    "    schoolDict = {} \n",
    "    schools = set(df['school_name'])\n",
    "    holla = set()\n",
    "    for school in schools: \n",
    "        if school not in schoolDict: \n",
    "            schoolDict[school] = Elo(school)\n",
    "    for index, row in df.iterrows(): \n",
    "        homeSchool = row[\"school_name\"]\n",
    "        oppSchool = row[\"opp_name\"]\n",
    "        if oppSchool not in schoolDict:\n",
    "            holla.add(oppSchool)\n",
    "            continue\n",
    "        oppRating = schoolDict[oppSchool].getRating()\n",
    "        schoolObj = schoolDict[homeSchool]\n",
    "        result = row[\"game_result\"]\n",
    "        if result == 'W': \n",
    "            schoolObj.game(1, oppRating)\n",
    "        else: \n",
    "            schoolObj.game(0, oppRating)\n",
    "        schoolDict[homeSchool] = schoolObj\n",
    "    print( len(holla) )\n",
    "    print( len(schools) )\n",
    "    print(holla)\n",
    "    return schoolDict\n",
    "main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
